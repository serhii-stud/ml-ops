{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23ddb3c3-44bb-453e-9261-22e3501d6281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.env-sample',\n",
       " '.gitignore',\n",
       " 'Dockerfile',\n",
       " 'Dockerfile.airflow',\n",
       " 'Dockerfile.mlflow',\n",
       " 'Dockerfile.ms',\n",
       " 'Dockerfile.train',\n",
       " 'README.md',\n",
       " 'dags',\n",
       " 'data',\n",
       " 'docker-compose.yaml',\n",
       " 'requirements-airflow.txt',\n",
       " 'requirements.txt',\n",
       " 'scripts',\n",
       " 'src',\n",
       " 'sm']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('/home/sagemaker-user/ml-ops/lab3')\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8780cee5-bf3f-40cf-88a0-053acebb1911",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "build_training_dataset() missing 2 required positional arguments: 'input_dir' and 'output_dir'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_prep\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdp\u001b[39;00m\n\u001b[1;32m      4\u001b[0m importlib\u001b[38;5;241m.\u001b[39mreload(dp)\n\u001b[0;32m----> 6\u001b[0m dv \u001b[38;5;241m=\u001b[39m \u001b[43mdp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_training_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdebug\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m dv\n",
      "\u001b[0;31mTypeError\u001b[0m: build_training_dataset() missing 2 required positional arguments: 'input_dir' and 'output_dir'"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import src.sm.processing.data_prep as dp\n",
    "\n",
    "importlib.reload(dp)\n",
    "\n",
    "dv = dp.build_training_dataset(data_version=\"debug\")\n",
    "dv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30c74af2-db32-4aeb-8da1-ac6873e5753e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n",
      "Using run_id: banking-prep-2025-12-29-17-05-46-7943a9\n",
      "Script path: /home/sagemaker-user/ml-ops/lab3/src/sm/processing/data_prep.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating processing-job with name banking-data-prep-2025-12-29-17-05-46-299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...............\u001b[34m>>> INPUT_DIR:  /opt/ml/processing/input\u001b[0m\n",
      "\u001b[34m>>> OUTPUT_DIR: /opt/ml/processing/output\u001b[0m\n",
      "\u001b[34m>>> DATA VERSION: banking-prep-2025-12-29-17-05-46-7943a9\u001b[0m\n",
      "\u001b[34m>>> Loading GOLDEN train from: /opt/ml/processing/input/historical/train.csv\n",
      "    GOLDEN train shape: (10003, 2)\u001b[0m\n",
      "\u001b[34m>>> Loading GOLDEN test  from: /opt/ml/processing/input/historical/test.csv\n",
      "    GOLDEN test shape:  (3080, 2)\u001b[0m\n",
      "\u001b[34m>>> FEEDBACK inference dir:   /opt/ml/processing/input/logs/inference\u001b[0m\n",
      "\u001b[34m>>> FEEDBACK corrections dir: /opt/ml/processing/input/logs/corrections\n",
      "    Found inference JSONL files:   13\n",
      "    Found corrections JSONL files: 3\n",
      "    Reading /opt/ml/processing/input/logs/inference/2025-12-22/batch_231355_dc83da00-77aa-4467-8d8d-8f6098bf9ad1.jsonl\n",
      "    Reading /opt/ml/processing/input/logs/inference/2025-12-22/0017b824-1d6c-43d1-ad53-0f9ee619c385.jsonl\n",
      "    Reading /opt/ml/processing/input/logs/inference/2025-12-22/003f4307-3740-4b25-bc00-095ac31cc7d7.jsonl\n",
      "    Reading /opt/ml/processing/input/logs/inference/2025-12-22/batch_225854_33d5dbe0-736d-4b29-a42a-8bf7f54f7743.jsonl\n",
      "    Reading /opt/ml/processing/input/logs/inference/2025-12-22/07cfadf2-785e-48f6-8dcf-c1b3f9f0fca7.jsonl\n",
      "    Reading /opt/ml/processing/input/logs/inference/2025-12-22/05bb2e72-9a4b-4d20-85c1-1664e5ae79ad.jsonl\n",
      "    Reading /opt/ml/processing/input/logs/inference/2025-12-19/b5aa54f1-6e2a-46c3-b2c3-c62b6367de4d.jsonl\n",
      "    Reading /opt/ml/processing/input/logs/inference/2025-12-19/ae315ca7-b6b7-4a24-a59b-303e29a20696.jsonl\n",
      "    Reading /opt/ml/processing/input/logs/inference/2025-12-19/2eb6cf43-b138-4f4d-895a-f71f71f56c04.jsonl\n",
      "    Reading /opt/ml/processing/input/logs/inference/2025-12-19/0cc55f39-ff12-47ce-bac3-cdb4a0f81724.jsonl\n",
      "    Reading /opt/ml/processing/input/logs/inference/2025-12-19/a58be50b-f0e4-4261-a8d1-43668b67c706.jsonl\n",
      "    Reading /opt/ml/processing/input/logs/inference/2025-12-25/batch_012008_ae958a25-367b-4b4d-a457-c11ce206fffa.jsonl\n",
      "    Reading /opt/ml/processing/input/logs/inference/2025-12-25/batch_011907_c1cec88d-5d8e-488f-a2f6-71849e5c3dab.jsonl\n",
      "    Total rows loaded: 99\n",
      "    Reading /opt/ml/processing/input/logs/corrections/2025-12-22/batch_e8b6486d-45f3-4028-afeb-50834a83b37b.jsonl\n",
      "    Reading /opt/ml/processing/input/logs/corrections/2025-12-25/batch_3e7381aa-fa12-4bcf-8c9d-95f8fca6a9ba.jsonl\n",
      "    Reading /opt/ml/processing/input/logs/corrections/2025-12-25/batch_9c9efe28-b988-4a16-8b91-d1cf01dd20e1.jsonl\n",
      "    Total rows loaded: 70\u001b[0m\n",
      "\u001b[34m>>> Merging inference + corrections on request_id (inner join)...\n",
      "    FEEDBACK merged rows: 70\u001b[0m\n",
      "\u001b[34m>>> FEEDBACK after cleaning: 70 samples\u001b[0m\n",
      "\u001b[34m>>> Splitting FEEDBACK into train/test...\n",
      "    FEEDBACK train shape: (56, 12)\n",
      "    FEEDBACK test  shape: (14, 12)\u001b[0m\n",
      "\u001b[34m>>> FINAL train shape: (10059, 12)\u001b[0m\n",
      "\u001b[34m>>> FINAL test shape:  (3094, 12)\n",
      "    Train source breakdown:\u001b[0m\n",
      "\u001b[34mgolden      10003\u001b[0m\n",
      "\u001b[34mfeedback       56\u001b[0m\n",
      "\u001b[34mName: source, dtype: int64\n",
      "    Test source breakdown:\u001b[0m\n",
      "\u001b[34mgolden      3080\u001b[0m\n",
      "\u001b[34mfeedback      14\u001b[0m\n",
      "\u001b[34mName: source, dtype: int64\u001b[0m\n",
      "\u001b[34m>>> Saving train to: /opt/ml/processing/output/train.parquet\u001b[0m\n",
      "\u001b[34m>>> Saving test to:  /opt/ml/processing/output/test.parquet\u001b[0m\n",
      "\u001b[34m>>> Updating latest aliases in: /opt/ml/processing/output/latest\u001b[0m\n",
      "\u001b[34m>>> DONE. Data version: banking-prep-2025-12-29-17-05-46-7943a9\u001b[0m\n",
      "\u001b[34m[SUMMARY] Built training data version: banking-prep-2025-12-29-17-05-46-7943a9\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ETL \n",
    "import os\n",
    "import sagemaker\n",
    "from datetime import datetime, UTC\n",
    "import uuid\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "\n",
    "def generate_run_id(prefix: str = \"run\") -> str:\n",
    "    \"\"\"Generate a unique run_id using UTC timestamp + short UUID.\"\"\"\n",
    "    timestamp = datetime.now(UTC).strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "    short_uuid = uuid.uuid4().hex[:6]\n",
    "    return f\"{prefix}-{timestamp}-{short_uuid}\"\n",
    "\n",
    "# SageMaker session and execution role\n",
    "sess = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "# Explicit project bucket (no default bucket)\n",
    "BUCKET = \"mlops-project-sm\"\n",
    "\n",
    "# Project S3 root prefix (your objects live under s3://bucket/data/...)\n",
    "S3_ROOT = \"data\"\n",
    "RAW_PREFIX = f\"{S3_ROOT}/raw\"\n",
    "PROCESSED_PREFIX = f\"{S3_ROOT}/processed\"\n",
    "\n",
    "# Generate run_id for this processing run\n",
    "run_id = generate_run_id(\"banking-prep\")\n",
    "print(\"Using run_id:\", run_id)\n",
    "\n",
    "# Input must point to a NON-empty S3 prefix\n",
    "raw_input_s3 = f\"s3://{BUCKET}/{RAW_PREFIX}/\"\n",
    "\n",
    "# Output for this run_id\n",
    "processed_output_s3 = f\"s3://{BUCKET}/{PROCESSED_PREFIX}/runs/{run_id}/\"\n",
    "\n",
    "# Absolute path to your processing script\n",
    "script_path = os.path.abspath(\"processing/data_prep.py\")\n",
    "reqs_path = os.path.abspath(\"processing/requirements.txt\")\n",
    "\n",
    "print(\"Script path:\", script_path)\n",
    "\n",
    "processor = SKLearnProcessor(\n",
    "    framework_version=\"1.2-1\",\n",
    "    role=role,\n",
    "    instance_type=\"ml.t3.medium\",\n",
    "    instance_count=1,\n",
    "    base_job_name=\"banking-data-prep\",\n",
    "    sagemaker_session=sess,\n",
    ")\n",
    "\n",
    "processor.run(\n",
    "    code=script_path,\n",
    "    arguments=[\n",
    "        \"--data_version\", \"auto\",\n",
    "        \"--input_dir\", \"/opt/ml/processing/input\",\n",
    "        \"--output_dir\", \"/opt/ml/processing/output\",\n",
    "        \"--run_id\", run_id,\n",
    "    ],\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=raw_input_s3,\n",
    "            destination=\"/opt/ml/processing/input\",\n",
    "        )\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            source=\"/opt/ml/processing/output\",\n",
    "            destination=processed_output_s3,\n",
    "        )\n",
    "    ],\n",
    "    logs=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f600d87-0d71-429e-aec5-1a05337a466e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SageMaker region: us-east-1\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "sess = sagemaker.Session()\n",
    "print(\"SageMaker region:\", sess.boto_region_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e01a1d43-abe7-4fcc-9a7c-5e34da92e682",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import re\n",
    "\n",
    "BUCKET = \"mlops-project-sm\"\n",
    "\n",
    "def resolve_data_uris(data_version: str | None):\n",
    "    \"\"\"\n",
    "    data_version:\n",
    "      - None / \"latest\" => use processed/latest/*\n",
    "      - otherwise       => use processed/runs/<data_version>/*\n",
    "    \"\"\"\n",
    "    if not data_version or data_version == \"latest\":\n",
    "        train_s3 = f\"s3://{BUCKET}/data/processed/latest/train_latest.parquet\"\n",
    "        test_s3  = f\"s3://{BUCKET}/data/processed/latest/test_latest.parquet\"\n",
    "        return train_s3, test_s3, \"latest\"\n",
    "\n",
    "    # Assume it's a run_id\n",
    "    train_s3 = f\"s3://{BUCKET}/data/processed/runs/{data_version}/train.parquet\"\n",
    "    test_s3  = f\"s3://{BUCKET}/data/processed/runs/{data_version}/test.parquet\"\n",
    "    return train_s3, test_s3, data_version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ece2a747-5f86-4795-87f6-12a250ff240d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data_version: latest\n",
      "s3://mlops-project-sm/data/processed/latest/train_latest.parquet\n",
      "s3://mlops-project-sm/data/processed/latest/test_latest.parquet\n"
     ]
    }
   ],
   "source": [
    "DATA_VERSION = \"latest\"  # or конкретный run_id\n",
    "train_s3, test_s3, effective_version = resolve_data_uris(DATA_VERSION)\n",
    "print(\"Using data_version:\", effective_version)\n",
    "print(train_s3)\n",
    "print(test_s3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f3f001f-41b9-4c04-a26d-67e1e347046a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "def get_latest_run_id():\n",
    "    s3 = boto3.client(\"s3\")\n",
    "    prefix = \"data/processed/runs/\"\n",
    "\n",
    "    paginator = s3.get_paginator(\"list_objects_v2\")\n",
    "    run_ids = set()\n",
    "\n",
    "    for page in paginator.paginate(Bucket=BUCKET, Prefix=prefix, Delimiter=\"/\"):\n",
    "        for cp in page.get(\"CommonPrefixes\", []):\n",
    "            # e.g. data/processed/runs/banking-prep-2025-12-25-.../\n",
    "            run_prefix = cp[\"Prefix\"]\n",
    "            run_id = run_prefix[len(prefix):].strip(\"/\")\n",
    "\n",
    "            # Optional: filter only your runs\n",
    "            if run_id.startswith(\"banking-prep-\"):\n",
    "                run_ids.add(run_id)\n",
    "\n",
    "    if not run_ids:\n",
    "        raise RuntimeError(f\"No runs found under s3://{BUCKET}/{prefix}\")\n",
    "\n",
    "    # Your run_id starts with timestamp; lexical sort works if format is consistent.\n",
    "    # If not consistent, better sort by LastModified of a known file (more complex).\n",
    "    return sorted(run_ids)[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58bbef44-4237-4da2-80e6-e407b6b21635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auto-selected run_id: banking-prep-2025-12-29-17-05-46-7943a9\n"
     ]
    }
   ],
   "source": [
    "DATA_VERSION = None  # None => auto\n",
    "if DATA_VERSION is None:\n",
    "    DATA_VERSION = get_latest_run_id()\n",
    "\n",
    "train_s3, test_s3, effective_version = resolve_data_uris(DATA_VERSION)\n",
    "print(\"Auto-selected run_id:\", effective_version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0de0fdb-b45a-4878-8833-fb9e4791d87a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::191072691166:role/ml-ops-SageMaker-ExecutionRole\n",
      "Training run_id: banking-train-2025-12-29-17-15-41-05dcb0\n",
      "Entry point: /home/sagemaker-user/ml-ops/lab3/src/sm/src/sm/training/train.py\n",
      "Reqs: /home/sagemaker-user/ml-ops/lab3/src/sm/src/sm/training/requirements.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_304/1057601797.py:10: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  ts = datetime.utcnow().strftime(\"%Y-%m-%d-%H-%M-%S\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ff0000; text-decoration-color: #ff0000\">╭─────────────────────────────── </span><span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">Traceback </span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #ff0000; text-decoration-color: #ff0000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> in &lt;module&gt;:53                                                                                   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">50 </span>                                                                                            <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">51 </span>inputs = {                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">52 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Channels \"train\" and \"test\" can point directly to a single file S3 URI</span>                <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>53 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"train\"</span>: TrainingInput(<span style=\"font-weight: bold; text-decoration: underline\">train_s3</span>, content_type=<span style=\"color: #808000; text-decoration-color: #808000\">\"application/x-parquet\"</span>),                 <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">54 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"test\"</span>: TrainingInput(test_s3, content_type=<span style=\"color: #808000; text-decoration-color: #808000\">\"application/x-parquet\"</span>),                   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">55 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                        <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">56 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Requirements channel: we upload local requirements.txt into this channel</span>              <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">NameError: </span>name <span style=\"color: #008700; text-decoration-color: #008700\">'train_s3'</span> is not defined\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;255;0;0m╭─\u001b[0m\u001b[38;2;255;0;0m──────────────────────────────\u001b[0m\u001b[38;2;255;0;0m \u001b[0m\u001b[1;38;2;255;0;0mTraceback \u001b[0m\u001b[1;2;38;2;255;0;0m(most recent call last)\u001b[0m\u001b[38;2;255;0;0m \u001b[0m\u001b[38;2;255;0;0m───────────────────────────────\u001b[0m\u001b[38;2;255;0;0m─╮\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m in <module>:53                                                                                   \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m50 \u001b[0m                                                                                            \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m51 \u001b[0minputs = {                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m52 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# Channels \"train\" and \"test\" can point directly to a single file S3 URI\u001b[0m                \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[31m❱ \u001b[0m53 \u001b[2m│   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33mtrain\u001b[0m\u001b[33m\"\u001b[0m: TrainingInput(\u001b[1;4mtrain_s3\u001b[0m, content_type=\u001b[33m\"\u001b[0m\u001b[33mapplication/x-parquet\u001b[0m\u001b[33m\"\u001b[0m),                 \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m54 \u001b[0m\u001b[2m│   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33mtest\u001b[0m\u001b[33m\"\u001b[0m: TrainingInput(test_s3, content_type=\u001b[33m\"\u001b[0m\u001b[33mapplication/x-parquet\u001b[0m\u001b[33m\"\u001b[0m),                   \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m55 \u001b[0m\u001b[2m│   \u001b[0m                                                                                        \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m56 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# Requirements channel: we upload local requirements.txt into this channel\u001b[0m              \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mNameError: \u001b[0mname \u001b[38;2;0;135;0m'train_s3'\u001b[0m is not defined\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train\n",
    "import sagemaker\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from datetime import datetime\n",
    "import uuid\n",
    "from pathlib import Path\n",
    "\n",
    "def generate_run_id(prefix=\"train\"):\n",
    "    ts = datetime.utcnow().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "    return f\"{prefix}-{ts}-{uuid.uuid4().hex[:6]}\"\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "print(role)\n",
    "\n",
    "BUCKET = \"mlops-project-sm\"\n",
    "run_id = generate_run_id(\"banking-train\")\n",
    "print(\"Training run_id:\", run_id)\n",
    "\n",
    "# Data produced by Processing Job (we use latest for now)\n",
    "# train_s3 = f\"s3://{BUCKET}/data/processed/latest/train_latest.parquet\"\n",
    "# test_s3  = f\"s3://{BUCKET}/data/processed/latest/test_latest.parquet\"\n",
    "\n",
    "# Local paths in Studio\n",
    "entry_point = os.path.abspath(\"src/sm/training/train.py\")\n",
    "reqs_local  = os.path.abspath(\"src/sm/training/requirements.txt\")\n",
    "\n",
    "print(\"Entry point:\", entry_point)\n",
    "print(\"Reqs:\", reqs_local)\n",
    "\n",
    "estimator = SKLearn(\n",
    "    entry_point=entry_point,\n",
    "    role=role,\n",
    "    framework_version=\"1.2-1\",\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    instance_count=1,\n",
    "    base_job_name=\"banking-training\",\n",
    "    sagemaker_session=sess,\n",
    "    hyperparameters={\n",
    "        # We pass where requirements will be mounted in the container\n",
    "        \"requirements\": \"/opt/ml/input/data/requirements/requirements.txt\",\n",
    "        # Filenames inside channels (we name files below)\n",
    "        \"train_file\": \"train_latest.parquet\",\n",
    "        \"test_file\": \"test_latest.parquet\",\n",
    "        \"max_features\": 50000,\n",
    "        \"C\": 2.0,\n",
    "    },\n",
    ")\n",
    "\n",
    "inputs = {\n",
    "    # Channels \"train\" and \"test\" can point directly to a single file S3 URI\n",
    "    \"train\": TrainingInput(train_s3, content_type=\"application/x-parquet\"),\n",
    "    \"test\": TrainingInput(test_s3, content_type=\"application/x-parquet\"),\n",
    "\n",
    "    # Requirements channel: we upload local requirements.txt into this channel\n",
    "    # For this, easiest is to put requirements.txt into S3 first OR use sagemaker.Session().upload_data\n",
    "}\n",
    "\n",
    "# Upload requirements.txt to S3 (simple and reliable)\n",
    "reqs_s3_prefix = f\"code/training/requirements/{run_id}\"\n",
    "reqs_s3_uri = sess.upload_data(path=reqs_local, bucket=BUCKET, key_prefix=reqs_s3_prefix)\n",
    "print(\"Uploaded requirements to:\", reqs_s3_uri)\n",
    "\n",
    "inputs[\"requirements\"] = TrainingInput(reqs_s3_uri, content_type=\"text/plain\")\n",
    "\n",
    "# Launch training\n",
    "estimator.fit(inputs=inputs, job_name=run_id, wait=True, logs=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864ac81a-0af3-46d4-843a-3ee2338e4a97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
